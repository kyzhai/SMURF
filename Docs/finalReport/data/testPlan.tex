\section{Test Plan}

During the development process of SMURF, to let everyone envolve in the development as much as possible, we adopt the slicing model, 
i.e., in each developing stage, everyone has a slice of work to work on.
One problem with this model is that different people need to work on a same job, 
one's change to the program can easily crash other people's work. 
As a result, extensive tests to ensure the quality of the software is crucial. 

\subsection{Testing Levels}
\subsubsection{Unit Testing}
For the lexer and parser, we generated a seperate toplevel executable to test their functionality (lexerParser.ml). 
This exectuable reads in SMURF programs, analyzes the input files with lexer and parser, generates the abstract syntax trees, 
 and then spits out the information stored in the ast trees.

\subsubsection{Integration Testing}
We tested the correctness of semantic checking and code generation models together with the lexer and parser models.
We generated the toplevel execuatuable with typecheck.ml for semantic checking, and with codegen.ml for code generation. 
The output of semantic checking is the semantic abstract syntax tree, 
which is the abstract syntax tree with types of every variables resolved.
The output of code generation is the bytecode for midi music generation.

We also tested the integration between our bytecode and the midi music generator in java.

\subsubsection{System Testing}
The end-to-end SMURF compiler accepts SMURF program and generates MIDIs. 
We listen the MIDIs generated by SMURF with music players to verify whether the sound was as expected.

\subsection{Test Suits}

The hierachy for SMURF test cases is shown in (figure~\ref{fig:testDir}). 
In each developing stage, everyone is in charge of a directory holding test cases constructed for the functionality he/she is working on. 
Every person needs to give the expecting output for his/her test cases in the {\bf exp} directory.
A case passes the test if its output is identical with the corresponding output in the {\bf exp} directory.
We have a script for testing all the test cases in the toplevel of the direcotry running all the test cases and comparing the results with the expect results given by every owner of the cases. 
The script gives the result about how many test cases passed and which test cases failed, if any. 
Before committing his/her result to the repository, everyone need to make sure the new change passed all the other people's cases. 
For the occasions that one's work need to change the output of other people's cases, 
he/she need to check the changes are as expected, 
and then generate new expected results for the cases before committing changes to repository.

Note that we test the cases that should run successfully and should fail with the same strategy. 
As long as the program is not broken, the output of failed cases should give the same exception message as that stored in {\bf exp} direcotry.

\begin{figure} [H]
\centering
\begin{tikzpicture}[%
grow via three points={one child at (0.5,-0.7) and
    two children at (0.5,-0.7) and (0.5,-1.4)},
    edge from parent path={(\tikzparentnode.south) |- (\tikzchildnode.west)}]

    \node {TEST_ROOT}
    child { node {parser-tests}}     
    child { node {semantic-tests}}
    child { node [selected] {codegen-tests}
        child { node [selected] {person1}
            child{ node {exp}
                child{ node {test-chord.out} }
                child{ node {test-system.out} }
                child{ node {test-fail-note.out} }
                child{ node [optional] {...} }
            }
            child [missing] {}              
            child [missing] {}              
            child [missing] {}              
            child [missing] {}              
            child{ node {test-chord.sm} }
            child{ node {test-system.sm} }
            child{ node {test-fail-note.sm} }
            child{ node [optional] {...} }
        }
        child [missing] {}              
        child [missing] {}              
        child [missing] {}              
        child [missing] {}              
        child [missing] {}              
        child [missing] {}              
        child [missing] {}              
        child [missing] {}              
        child [missing] {}              
        child { node {person2}}
        child { node {person3}}
        child { node {person4}}
        child { node {person5}}
    };
\end{tikzpicture}
\caption{The direcotry of SMURF test cases}
\label{fig:testDir}
\end{figure}

\subsection{Example Test Cases}
Below we give several sample test cases and their expected output for SMURF.

\subsubsection{parser-tests}
Note that the programs that pass parser testing may not be semantically correct.
\lstset{ language=[Objective]Caml }
\lstinputlisting{../../Code/tests/parser-tests/kyzhai/test1.sm}

\subsubsection{semantic-tests}
\lstset{ language=[Objective]Caml }
\lstinputlisting{../../Code/tests/parser-tests/kyzhai/test1.sm}

\subsubsection{codegen-tests}
\lstset{ language=[Objective]Caml }
\lstinputlisting{../../Code/tests/parser-tests/kyzhai/test1.sm}
